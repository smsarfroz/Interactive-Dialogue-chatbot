{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/smsarfroz/Interactive-Dialogue-chatbot/blob/main/Chatbot_made_through_python_and_nltk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cYv-IAgApQ9l"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import nltk\n",
        "import string\n",
        "import random\n",
        "import sqlite3\n",
        "from textblob import TextBlob\n",
        "from collections import defaultdict"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "covpQ-CaZr7U",
        "outputId": "2eae0479-e1e5-4d5e-f055-1b362fa4ae8e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: textblob in /usr/local/lib/python3.10/dist-packages (0.17.1)\n",
            "Requirement already satisfied: nltk>=3.1 in /usr/local/lib/python3.10/dist-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (8.1.4)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (1.3.1)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (2022.10.31)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk>=3.1->textblob) (4.65.0)\n"
          ]
        }
      ],
      "source": [
        "pip install textblob"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yTxSzKTOb-2F"
      },
      "outputs": [],
      "source": [
        "# Initializing conversation history and state\n",
        "conversation_history = []\n",
        "state = defaultdict(list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UwA7KX8Lprch",
        "outputId": "1bbbc3df-b2a5-4a2d-d25e-8372dbcb4f47"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n"
          ]
        }
      ],
      "source": [
        "f=open('chatbot.txt' , 'r' , errors = 'ignore' )\n",
        "f=open('dialogs.txt' , 'r' , errors = 'ignore' )\n",
        "#f=open('Conversation[1].csv' , 'r' , errors = 'ignore' )\n",
        "raw_doc=f.read( )\n",
        "raw_doc=raw_doc.lower() #converts text to lowercase\n",
        "nltk.download( 'punkt') #Us1ng the Punkt tokenizer\n",
        "nltk.download( 'wordnet') #Using the WordNet dictionary\n",
        "sent_tokens = nltk.sent_tokenize(raw_doc)#Converts doc to list of sentences\n",
        "\n",
        "word_tokens = nltk.word_tokenize(raw_doc) #Converts doc to list of wc\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K28mkCcGr7vh",
        "outputId": "90714800-68e5-4dc1-e40b-5a1f641c1b4f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hi, how are you doing?', \"i'm fine.\"]"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "sent_tokens[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ajZ1jYjks_GT",
        "outputId": "b549df2e-5bf2-47ce-9f53-a9a06ea94bdd"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['hi', ',']"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "word_tokens[:2]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TVsdtTujtOek"
      },
      "outputs": [],
      "source": [
        "lemmer= nltk.stem.WordNetLemmatizer()\n",
        "\n",
        "#WordNet is a semantically-oriented dictionary of English included in NLTK.\n",
        "def LemTokens(tokens):\n",
        "  return [lemmer.lemmatize(token) for token in tokens]\n",
        "remove_punct_dict = dict((ord(punct), None) for punct in string. punctuation)\n",
        "def LemNormalize(text):\n",
        "  return LemTokens(nltk.word_tokenize(text.lower().translate(remove_punct_dict)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-lIBatQuu5nZ"
      },
      "outputs": [],
      "source": [
        "GREET_INPUTS = (\"hello\", \"hi\",\"greetings\", \"sup\",\"what's up\", \"hey\",)\n",
        "\n",
        "GREET_RESPONSES =[\"hi\", \"hey\",\"*nods*\",\"hi there\",\"hello\", \"I am glad! You are talking to me\"]\n",
        "def greet(sentence):\n",
        "  for word in sentence.split():\n",
        "    if word.lower() in GREET_INPUTS:\n",
        "      return random.choice(GREET_RESPONSES)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A6-VLgIvIffN"
      },
      "outputs": [],
      "source": [
        "suggestions = [\"tell me about your hobbies\",  \"how can I contact customer support?\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzStPNknv53A"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5atbuJPk9uBs"
      },
      "outputs": [],
      "source": [
        "def create_feedback_table():\n",
        "    conn = sqlite3.connect('feedback.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Create the feedback table if it doesn't exist\n",
        "    c.execute('''CREATE TABLE IF NOT EXISTS feedback (\n",
        "                    response text,\n",
        "                    feedback text\n",
        "                )''')\n",
        "\n",
        "    # Commit the changes and close the connection\n",
        "    conn.commit()\n",
        "    conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Rb3jr9j-9wEr"
      },
      "outputs": [],
      "source": [
        "def collect_feedback(response):\n",
        "    # ask the user to provide feedback\n",
        "    print(\"BOT: How would you rate my response? (1-5)\")\n",
        "    feedback = input(\"User: \")\n",
        "\n",
        "    # Store the feedback in the database\n",
        "    save_feedback_to_database(response, feedback)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Z3ETJle9zQD"
      },
      "outputs": [],
      "source": [
        "def save_feedback_to_database(response, feedback):\n",
        "    conn = sqlite3.connect('feedback.db')\n",
        "    c = conn.cursor()\n",
        "\n",
        "    # Insert the feedback into the database\n",
        "    c.execute(\"INSERT INTO feedback (response, feedback) VALUES (?, ?)\", (response, feedback))\n",
        "\n",
        "    # Commit the changes and close the connection\n",
        "    conn.commit()\n",
        "    conn.close()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c4_e4YRI95RL"
      },
      "outputs": [],
      "source": [
        "create_feedback_table()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ir_AvCPHwDHt"
      },
      "outputs": [],
      "source": [
        "def response(user_response):\n",
        "  robo1_response=''\n",
        "  TfidfVec=TfidfVectorizer(tokenizer=LemNormalize,stop_words='english')\n",
        "  tfidf = TfidfVec.fit_transform(sent_tokens)\n",
        "  vals=cosine_similarity(tfidf[-1],tfidf)\n",
        "  idx=vals.argsort()[0][-2]\n",
        "  flat=vals.flatten()\n",
        "  flat.sort( )\n",
        "  req_tfidf=flat[-2]\n",
        "  blob = TextBlob(user_response)\n",
        "  sentiment = blob.sentiment.polarity\n",
        "\n",
        "\n",
        "  if sentiment > 0:\n",
        "      # Handle positive response logic\n",
        "      robo1_response += \"I'm glad to hear that!\"\n",
        "  elif sentiment < 0:\n",
        "      # Handle negative response logic\n",
        "      robo1_response += \"I'm sorry to hear that. How can I assist you?\"\n",
        "  if(req_tfidf==0):\n",
        "    robo1_response=robo1_response+\"l am sorry! I didn't understand you. \"\n",
        "    return robo1_response\n",
        "  else:\n",
        "    robo1_response=robo1_response+sent_tokens[idx]\n",
        "    return robo1_response\n",
        "\n",
        "  # Add user response to conversation history\n",
        "  conversation_history.append(user_response)\n",
        "\n",
        "  # Update state based on conversation history\n",
        "  state[\"user\"].append(user_response)\n",
        "  state[\"bot\"].append(robo1_response)\n",
        "\n",
        "  dialogue_response = generate_dialogue_response(user_response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KY_4s9YDeGJu"
      },
      "outputs": [],
      "source": [
        "def generate_dialogue_response(user_response):\n",
        "    # Implement your dialogue manager logic here\n",
        "    if len(conversation_history) > 1:\n",
        "        # Generate a response based on the previous user input and bot response\n",
        "        previous_user_input = conversation_history[-2]\n",
        "        previous_bot_response = state[\"bot\"][-1]\n",
        "\n",
        "        # Customize your dialogue manager logic based on the previous interaction\n",
        "        if previous_user_input == \"Tell me a joke\" and \"joke\" in previous_bot_response:\n",
        "            return \"Sure! Why don't scientists trust atoms? Because they make up everything!\"\n",
        "        elif previous_user_input == \"What is your favorite movie?\" and \"movie\" in previous_bot_response:\n",
        "            return \"I am a bot, so I don't have favorite movies. But I can recommend some popular ones!\"\n",
        "\n",
        "    # If no specific context matches, generate a generic response\n",
        "    return \"I'm sorry, I didn't understand. Can you please rephrase or provide more information?\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "x2hYBNqgzudB",
        "outputId": "504add17-e3f6-4f08-944c-d8c121fa9331"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "BOT: MY name is Chatnlt. Let's have a talk! and,if you want to quit any time ,just type Bye\n",
            "BOT: hey\n",
            "BOT: "
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.10/dist-packages/sklearn/feature_extraction/text.py:409: UserWarning: Your stop_words may be inconsistent with your preprocessing. Tokenizing the stop words generated tokens ['ha', 'le', 'u', 'wa'] not in stop_words.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "i don't like that man.\n",
            "BOT: How would you rate my response? (1-5)\n",
            "BOT: I'm glad to hear that!i liked it.\n",
            "BOT: How would you rate my response? (1-5)\n"
          ]
        }
      ],
      "source": [
        "flag=True\n",
        "print(\"BOT: MY name is Chatnlt. Let's have a talk! and,if you want to quit any time ,just type Bye\")\n",
        "while(flag==True):\n",
        "  user_response=input()\n",
        "  user_response=user_response.lower()\n",
        "  if(user_response!='bye'):\n",
        "      if(user_response=='thanks' or user_response=='thank you'):\n",
        "        flag=False\n",
        "        print(\"BOT: You are welcome.. \")\n",
        "      else:\n",
        "          if(greet(user_response)!=None):\n",
        "            print(\"BOT: \"+greet(user_response))\n",
        "          else:\n",
        "            sent_tokens.append(user_response)\n",
        "            word_tokens=word_tokens+nltk.word_tokenize(user_response)\n",
        "            final_words=list(set(word_tokens))\n",
        "            print(\"BOT: \",end=\"\")\n",
        "\n",
        "            dialogue_response = generate_dialogue_response(user_response)\n",
        "\n",
        "            chatbot_response = response(user_response)\n",
        "            print(chatbot_response)\n",
        "            collect_feedback(chatbot_response)\n",
        "\n",
        "            sent_tokens.remove(user_response)\n",
        "\n",
        "  else:\n",
        "     flag=False\n",
        "     print(\"BOT: Goodbye! Take care\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOovffiumMudCnIA+SksDTu",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}